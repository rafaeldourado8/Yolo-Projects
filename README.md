üñêÔ∏è Controle de M√≠dia por Gestos com YOLOv8 e PyAutoGUI
Este projeto utiliza Vis√£o Computacional (YOLOv8) para detectar gestos de m√£o em tempo real atrav√©s da webcam e traduzi-los em comandos de teclado para controlar aplicativos de m√≠dia no seu computador (como Spotify, YouTube, VLC, etc.).
‚öôÔ∏è Tecnologias Utilizadas
Python: Linguagem principal do projeto.

OpenCV (cv2): Para captura de v√≠deo da webcam e processamento de imagem.

Ultralytics (YOLO): Para carregar e executar o modelo de detec√ß√£o de objetos (YOLOv8).

PyAutoGUI: Para simular o pressionamento de teclas do sistema operacional.

Time: Para gerenciar o sistema de cooldown.

üöÄ Como Configurar e Rodar
1. Pr√©-requisitos
Certifique-se de ter o Python instalado em seu sistema.

2. Instala√ß√£o de Depend√™ncias
Instale todas as bibliotecas necess√°rias via pip:

pip install opencv-python ultralytics pyautogui

3. Modelo YOLOv8
O script espera que o modelo treinado esteja no formato PyTorch (.pt).

Baixe ou treine seu modelo e salve-o na mesma pasta do script com o nome best.pt.

O modelo deve ser treinado para detectar classes de gestos, como fist, open_hand, thumbs_down, etc.

4. Configura√ß√£o Inicial

MODEL_PATH	Caminho do arquivo do modelo.	'best.pt'
CONF_THRESHOLD	Limite de confian√ßa para aceitar uma detec√ß√£o (0.0 a 1.0).	0.7
COOLDOWN_PERIOD	Tempo (em segundos) que se deve esperar entre a√ß√µes.	2.0
WEBCAM_INDEX	√çndice da sua webcam (geralmente 0 para a c√¢mera principal).	0
USE_IP_WEBCAM	Mude para True se usar um celular como c√¢mera (ex: IP Webcam).	False
IP_WEBCAM_URL	URL do stream da IP Webcam (se USE_IP_WEBCAM=True).	'http://'

5. Mapeamento de Gestos

Ajuste o dicion√°rio GESTURE_MAP para definir qual gesto (nome da classe) aciona qual tecla. As classes devem corresponder √†s do seu modelo.

GESTURE_MAP = {
    'fist': 'space',        # Ex: Punho Fechado -> Play/Pause
    'open_hand': 'volumeup',    # Ex: M√£o Aberta -> Aumentar Volume
    'thumbs_down': 'volumedown', # Ex: Polegar para Baixo -> Diminuir Volume
    # Adicione mais gestos conforme seu modelo...
}

6. Execu√ß√£o

Rode o script no seu terminal:
python seu_script_nome.py

üíª Funcionamento do C√≥digo
O fluxo de trabalho do script segue uma estrutura robusta para garantir a detec√ß√£o precisa e a estabilidade dos comandos:

Inicializa√ß√£o: O modelo YOLO √© carregado (YOLO('best.pt')) e a conex√£o com a webcam √© estabelecida.

Loop Principal (Por Frame):

O frame lido da webcam √© espelhado (cv2.flip) para uma experi√™ncia mais intuitiva.

A infer√™ncia YOLO √© executada (model(frame)).

Processamento dos Resultados:

O c√≥digo itera sobre todas as detec√ß√µes, desenhando caixas delimitadoras e r√≥tulos para gestos com confian√ßa acima de CONF_THRESHOLD.

O gesto v√°lido com a maior confian√ßa √© selecionado para ser o comando potencial (current_action).

L√≥gica de Cooldown e Acionamento:

O script verifica duas condi√ß√µes cruciais:

Um comando v√°lido (current_action) foi detectado.

O tempo de COOLDOWN_PERIOD passou desde a √∫ltima a√ß√£o (last_action_time).

Se ambas as condi√ß√µes forem atendidas, o comando de teclado √© enviado via pyautogui.press(current_action), e o last_action_time √© atualizado.

Essa l√≥gica de cooldown √© fundamental para evitar o disparo cont√≠nuo de comandos, tornando o controle pr√°tico e responsivo ao inv√©s de ca√≥tico.
